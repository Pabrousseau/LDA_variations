{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cSampler import LdaSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "dictionary = corpora.Dictionary.load('reviews.dict') \n",
    "corpus = corpora.MmCorpus('reviews.mm')\n",
    "import numpy as np\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=matutils.corpus2csc(corpus).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# attraction tags\n",
    "A = {}\n",
    "for line in open('attractions.txt'):\n",
    "    A[line[0:12]] = line[17:-1].split(\"+\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R=\"0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+1+1+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0\"\n",
    "A[\"VN00036-0646\"] = R.split(\"+\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user tags\n",
    "U = {}\n",
    "for line in open('users.txt'):\n",
    "    U[line[0:32]] = line[37:-1].split(\"+\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = \"0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0\"\n",
    "U[\"A06BEC3C65A7516446886BDDE810883B\"] = R.split(\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RU = \"0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0\"\n",
    "RA=\"0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+1+1+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0\"\n",
    "XA=[]\n",
    "XU=[]\n",
    "for line in open('reviews.txt'):\n",
    "    try:\n",
    "        XA.append(A[line[0:12]])\n",
    "    except KeyError:\n",
    "        XA.append(RA.split(\"+\"))\n",
    "                \n",
    "    if line[17:24]!=\"unknown\":\n",
    "        XU.append(U[line[17:49]])\n",
    "    else:\n",
    "        XU.append(RU.split(\"+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XA=np.asarray(XA)\n",
    "XU=np.asarray(XU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler initializing.\n",
      "\n",
      "Initial likekihood: -290646382.73838294\n",
      "\n",
      "Iteration 0\n",
      "\tLog-likelihood: -289594031.84119296\n",
      "Iteration 1\n",
      "\tLog-likelihood: -289204757.82190144\n",
      "Iteration 2\n",
      "\tLog-likelihood: -288905466.95399296\n",
      "Iteration 3\n",
      "\tLog-likelihood: -288599080.74303555\n",
      "Iteration 4\n",
      "\tLog-likelihood: -288270647.01151836\n",
      "Iteration 5\n",
      "\tLog-likelihood: -287880575.007342\n",
      "Iteration 6\n",
      "\tLog-likelihood: -287376215.1431957\n",
      "Iteration 7\n",
      "\tLog-likelihood: -286758744.60366035\n",
      "Iteration 8\n",
      "\tLog-likelihood: -285975304.5491995\n",
      "Iteration 9\n",
      "\tLog-likelihood: -284885423.9890128\n",
      "10133.35411453247\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "m = 200000\n",
    "k = 1428142\n",
    "a=time.time()\n",
    "sampler = LdaSampler(50)\n",
    "liks=sampler.fit(X[0:m,],XA.astype(int)[0:m,:],XU.astype(int)[0:m,:],maxiter=10,verbose=1)\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 topics\n",
      "10 iterations\n",
      "for 2000 data points 92.50147604942322\n",
      "for 20000 data points 381.87616777420044\n",
      "\n",
      "100 topics\n",
      "10 iterations\n",
      "for 2000 data points 96.126384973526\n",
      "for 20000 data points 423.7120044231415\n",
      "for 200000 data points 6809.282732486725\n",
      "100 iterations\n",
      "for 2000 data points 495.34568881988525\n",
      "for 20000 data points 3701.6093814373016\n",
      "\n",
      "1000 topics\n",
      "10 iterations\n",
      "for 2000 data points 171.51206469535828\n",
      "for 20000 data points 957.0012774467468\n"
     ]
    }
   ],
   "source": [
    "print(\"10 topics\")\n",
    "print(\"10 iterations\")\n",
    "print(\"for 2000 data points \" + str(92.50147604942322))\n",
    "print(\"for 20000 data points \" + str(381.87616777420044))\n",
    "print()\n",
    "print(\"100 topics\")\n",
    "print(\"10 iterations\")\n",
    "print(\"for 2000 data points \" + str(96.126384973526))\n",
    "print(\"for 20000 data points \" + str(423.7120044231415))\n",
    "print(\"for 200000 data points \" + str(6809.282732486725))\n",
    "print(\"100 iterations\")\n",
    "print(\"for 2000 data points \" + str(495.34568881988525))\n",
    "print(\"for 20000 data points \" + str(3701.6093814373016))\n",
    "print()\n",
    "print(\"1000 topics\")\n",
    "print(\"10 iterations\")\n",
    "print(\"for 2000 data points \" + str(171.51206469535828))\n",
    "print(\"for 20000 data points \" + str(957.0012774467468))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22386.17725019\n"
     ]
    }
   ],
   "source": [
    "x = 1400000\n",
    "print(1.594518052*(1/100)*x + 62.92452219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 20 data points 64.22826838493347\n",
      "for 200 data points 66.77770185470581\n"
     ]
    }
   ],
   "source": [
    "print(\"for 20 data points \" + str(64.22826838493347))\n",
    "print(\"for 200 data points \" + str(66.77770185470581))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.90791273117065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "125.90791273117065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sampler, open( \"LDA200k10it.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "dict_stuff = sampler.__dict__\n",
    "del dict_stuff['topics']\n",
    "with open('sampler.json', 'w') as fp:\n",
    "    json.dump(dict_stuff, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
